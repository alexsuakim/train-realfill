{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7M37t-cRkNDf",
        "outputId": "deba5e20-1f49-45db-b53b-096217ceafd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'realfill'...\n",
            "remote: Enumerating objects: 192, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 192 (delta 29), reused 0 (delta 0), pack-reused 137\u001b[K\n",
            "Receiving objects: 100% (192/192), 1.22 MiB | 9.36 MiB/s, done.\n",
            "Resolving deltas: 100% (81/81), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/thuanz123/realfill.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTXUPQrrtMZF",
        "outputId": "ff54182e-d63f-4289-f084-4481067b874c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/realfill\n",
            "\u001b[0m\u001b[01;34mdata\u001b[0m/  infer.py  LICENSE  README.md  requirements.txt  train_realfill.py\n"
          ]
        }
      ],
      "source": [
        "%cd realfill\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hcWLJk3kq3i",
        "outputId": "b741d90d-7448-4647-f4c1-f7518431d8de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting diffusers==0.20.1 (from -r /content/realfill/requirements.txt (line 1))\n",
            "  Downloading diffusers-0.20.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate==0.23.0 (from -r /content/realfill/requirements.txt (line 2))\n",
            "  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.34.0 (from -r /content/realfill/requirements.txt (line 3))\n",
            "  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting peft==0.5.0 (from -r /content/realfill/requirements.txt (line 4))\n",
            "  Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==2.0.1 (from -r /content/realfill/requirements.txt (line 5))\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.15.2 (from -r /content/realfill/requirements.txt (line 6))\n",
            "  Downloading torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ftfy==6.1.1 (from -r /content/realfill/requirements.txt (line 7))\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard==2.14.0 (from -r /content/realfill/requirements.txt (line 8))\n",
            "  Downloading tensorboard-2.14.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Jinja2==3.1.2 (from -r /content/realfill/requirements.txt (line 9))\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.20.1->-r /content/realfill/requirements.txt (line 1)) (7.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.20.1->-r /content/realfill/requirements.txt (line 1)) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.20.1->-r /content/realfill/requirements.txt (line 1)) (0.20.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.20.1->-r /content/realfill/requirements.txt (line 1)) (1.25.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.20.1->-r /content/realfill/requirements.txt (line 1)) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.20.1->-r /content/realfill/requirements.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.20.1->-r /content/realfill/requirements.txt (line 1)) (0.4.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.20.1->-r /content/realfill/requirements.txt (line 1)) (9.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.23.0->-r /content/realfill/requirements.txt (line 2)) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.23.0->-r /content/realfill/requirements.txt (line 2)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.23.0->-r /content/realfill/requirements.txt (line 2)) (6.0.1)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers==4.34.0->-r /content/realfill/requirements.txt (line 3))\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0->-r /content/realfill/requirements.txt (line 3)) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r /content/realfill/requirements.txt (line 5)) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r /content/realfill/requirements.txt (line 5)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r /content/realfill/requirements.txt (line 5)) (3.2.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1->-r /content/realfill/requirements.txt (line 5))\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1->-r /content/realfill/requirements.txt (line 5))\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1->-r /content/realfill/requirements.txt (line 5))\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1->-r /content/realfill/requirements.txt (line 5))\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1->-r /content/realfill/requirements.txt (line 5))\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1->-r /content/realfill/requirements.txt (line 5))\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1->-r /content/realfill/requirements.txt (line 5))\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1->-r /content/realfill/requirements.txt (line 5))\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1->-r /content/realfill/requirements.txt (line 5))\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1->-r /content/realfill/requirements.txt (line 5))\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1->-r /content/realfill/requirements.txt (line 5))\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0 (from torch==2.0.1->-r /content/realfill/requirements.txt (line 5))\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy==6.1.1->-r /content/realfill/requirements.txt (line 7)) (0.2.13)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.14.0->-r /content/realfill/requirements.txt (line 8)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.14.0->-r /content/realfill/requirements.txt (line 8)) (1.60.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.14.0->-r /content/realfill/requirements.txt (line 8)) (2.27.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard==2.14.0->-r /content/realfill/requirements.txt (line 8))\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.14.0->-r /content/realfill/requirements.txt (line 8)) (3.5.2)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.14.0->-r /content/realfill/requirements.txt (line 8)) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.14.0->-r /content/realfill/requirements.txt (line 8)) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.14.0->-r /content/realfill/requirements.txt (line 8)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.14.0->-r /content/realfill/requirements.txt (line 8)) (3.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.14.0->-r /content/realfill/requirements.txt (line 8)) (0.42.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2==3.1.2->-r /content/realfill/requirements.txt (line 9)) (2.1.5)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->-r /content/realfill/requirements.txt (line 5)) (3.27.9)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1->-r /content/realfill/requirements.txt (line 5))\n",
            "  Downloading lit-17.0.6.tar.gz (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.14.0->-r /content/realfill/requirements.txt (line 8)) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.14.0->-r /content/realfill/requirements.txt (line 8)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.14.0->-r /content/realfill/requirements.txt (line 8)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard==2.14.0->-r /content/realfill/requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.20.1->-r /content/realfill/requirements.txt (line 1)) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.20.1->-r /content/realfill/requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.20.1->-r /content/realfill/requirements.txt (line 1)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.20.1->-r /content/realfill/requirements.txt (line 1)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.20.1->-r /content/realfill/requirements.txt (line 1)) (2024.2.2)\n",
            "Collecting huggingface-hub>=0.13.2 (from diffusers==0.20.1->-r /content/realfill/requirements.txt (line 1))\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.20.1->-r /content/realfill/requirements.txt (line 1)) (3.17.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->-r /content/realfill/requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.14.0->-r /content/realfill/requirements.txt (line 8)) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard==2.14.0->-r /content/realfill/requirements.txt (line 8)) (3.2.2)\n",
            "Building wheels for collected packages: lit\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-17.0.6-py3-none-any.whl size=93255 sha256=da4cb2f8852a00c11b75e7f9a44519eb31da2b1a9ea1c3c87c66066c6588624b\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/dd/04/47d42976a6a86dc2ab66d7518621ae96f43452c8841d74758a\n",
            "Successfully built lit\n",
            "Installing collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, Jinja2, ftfy, nvidia-cusolver-cu11, nvidia-cudnn-cu11, huggingface-hub, tokenizers, google-auth-oauthlib, diffusers, transformers, tensorboard, triton, torch, accelerate, torchvision, peft\n",
            "  Attempting uninstall: Jinja2\n",
            "    Found existing installation: Jinja2 3.1.3\n",
            "    Uninstalling Jinja2-3.1.3:\n",
            "      Successfully uninstalled Jinja2-3.1.3\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.1\n",
            "    Uninstalling tokenizers-0.15.1:\n",
            "      Successfully uninstalled tokenizers-0.15.1\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.0\n",
            "    Uninstalling google-auth-oauthlib-1.2.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu121\n",
            "    Uninstalling torch-2.1.0+cu121:\n",
            "      Successfully uninstalled torch-2.1.0+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.16.0+cu121\n",
            "    Uninstalling torchvision-0.16.0+cu121:\n",
            "      Successfully uninstalled torchvision-0.16.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "tensorflow 2.15.0 requires tensorboard<2.16,>=2.15, but you have tensorboard 2.14.0 which is incompatible.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Jinja2-3.1.2 accelerate-0.23.0 diffusers-0.20.1 ftfy-6.1.1 google-auth-oauthlib-1.0.0 huggingface-hub-0.17.3 lit-17.0.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 peft-0.5.0 tensorboard-2.14.0 tokenizers-0.14.1 torch-2.0.1 torchvision-0.15.2 transformers-4.34.0 triton-2.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -r /content/realfill/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYgiy8a9k5yA",
        "outputId": "bc0c6abf-a9fc-4c12-c51e-db4c4b55ab6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/root/.cache/huggingface/accelerate/default_config.yaml')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from accelerate.utils import write_basic_config\n",
        "write_basic_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQexbUktpzdp",
        "outputId": "779ff88a-02c5-4c6f-d681-fbbcb7e7b9e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: MODEL_NAME=stabilityai/stable-diffusion-2-inpainting\n",
            "env: TRAIN_DIR=data/flowerwoman\n",
            "env: OUTPUT_DIR=flowerwoman-model\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
            "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
            "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
            "2024-02-14 14:40:15.650526: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-14 14:40:15.650587: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-14 14:40:15.652350: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-14 14:40:16.931433: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "02/14/2024 14:40:18 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: no\n",
            "\n",
            "Downloading (…)okenizer_config.json: 100% 829/829 [00:00<00:00, 4.60MB/s]\n",
            "Downloading tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 15.9MB/s]\n",
            "Downloading tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 118MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 460/460 [00:00<00:00, 2.23MB/s]\n",
            "Downloading (…)cheduler_config.json: 100% 308/308 [00:00<00:00, 1.95MB/s]\n",
            "{'timestep_spacing', 'variance_type', 'prediction_type', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
            "Downloading (…)_encoder/config.json: 100% 638/638 [00:00<00:00, 3.90MB/s]\n",
            "Downloading model.safetensors: 100% 1.36G/1.36G [00:06<00:00, 202MB/s]\n",
            "Downloading vae/config.json: 100% 616/616 [00:00<00:00, 3.50MB/s]\n",
            "Downloading (…)ch_model.safetensors: 100% 335M/335M [00:01<00:00, 202MB/s]\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "Downloading unet/config.json: 100% 914/914 [00:00<00:00, 3.86MB/s]\n",
            "Downloading (…)ch_model.safetensors: 100% 3.46G/3.46G [00:18<00:00, 191MB/s]\n",
            "{'encoder_hid_dim', 'time_cond_proj_dim', 'resnet_out_scale_factor', 'mid_block_type', 'conv_in_kernel', 'upcast_attention', 'projection_class_embeddings_input_dim', 'addition_embed_type_num_heads', 'class_embed_type', 'time_embedding_type', 'timestep_post_act', 'transformer_layers_per_block', 'time_embedding_act_fn', 'conv_out_kernel', 'cross_attention_norm', 'attention_type', 'time_embedding_dim', 'encoder_hid_dim_type', 'resnet_time_scale_shift', 'addition_embed_type', 'only_cross_attention', 'num_attention_heads', 'resnet_skip_time_act', 'addition_time_embed_dim', 'class_embeddings_concat', 'mid_block_only_cross_attention', 'num_class_embeds'} was not found in config. Values will be initialized to default values.\n",
            "02/14/2024 14:40:56 - INFO - __main__ - ***** Running training *****\n",
            "02/14/2024 14:40:56 - INFO - __main__ -   Num examples = 4\n",
            "02/14/2024 14:40:56 - INFO - __main__ -   Num batches each epoch = 1\n",
            "02/14/2024 14:40:56 - INFO - __main__ -   Num Epochs = 2000\n",
            "02/14/2024 14:40:56 - INFO - __main__ -   Instantaneous batch size per device = 16\n",
            "02/14/2024 14:40:56 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "02/14/2024 14:40:56 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "02/14/2024 14:40:56 - INFO - __main__ -   Total optimization steps = 2000\n",
            "Steps:   5% 100/2000 [02:06<39:25,  1.24s/it, loss=0.136]02/14/2024 14:43:02 - INFO - __main__ - Running validation... \n",
            "Generating 4 images\n",
            "\n",
            "Downloading model_index.json: 100% 544/544 [00:00<00:00, 2.95MB/s]\n",
            "\n",
            "Fetching 9 files:   0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Downloading (…)rocessor_config.json: 100% 342/342 [00:00<00:00, 1.48MB/s]\n",
            "\n",
            "Fetching 9 files: 100% 9/9 [00:00<00:00, 45.65it/s]\n",
            "\n",
            "Loading pipeline components...:   0% 0/6 [00:00<?, ?it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  33% 2/6 [00:00<00:00, 17.98it/s]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  83% 5/6 [00:00<00:00,  7.82it/s]\u001b[A{'encoder_hid_dim', 'time_cond_proj_dim', 'resnet_out_scale_factor', 'mid_block_type', 'conv_in_kernel', 'upcast_attention', 'projection_class_embeddings_input_dim', 'addition_embed_type_num_heads', 'class_embed_type', 'time_embedding_type', 'timestep_post_act', 'transformer_layers_per_block', 'time_embedding_act_fn', 'conv_out_kernel', 'cross_attention_norm', 'attention_type', 'time_embedding_dim', 'encoder_hid_dim_type', 'resnet_time_scale_shift', 'addition_embed_type', 'only_cross_attention', 'num_attention_heads', 'resnet_skip_time_act', 'addition_time_embed_dim', 'class_embeddings_concat', 'mid_block_only_cross_attention', 'num_class_embeds'} was not found in config. Values will be initialized to default values.\n",
            "Loaded unet as UNet2DConditionModel from `unet` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loading pipeline components...: 100% 6/6 [00:00<00:00,  6.79it/s]\n",
            "{'timestep_spacing', 'variance_type', 'prediction_type', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  10% 200/2000 [05:09<37:57,  1.27s/it, loss=0.1]02/14/2024 14:46:05 - INFO - __main__ - Running validation... \n",
            "Generating 4 images\n",
            "\n",
            "Loading pipeline components...:   0% 0/6 [00:00<?, ?it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  33% 2/6 [00:00<00:00, 18.23it/s]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  83% 5/6 [00:00<00:00,  7.71it/s]\u001b[A{'encoder_hid_dim', 'time_cond_proj_dim', 'resnet_out_scale_factor', 'mid_block_type', 'conv_in_kernel', 'upcast_attention', 'projection_class_embeddings_input_dim', 'addition_embed_type_num_heads', 'class_embed_type', 'time_embedding_type', 'timestep_post_act', 'transformer_layers_per_block', 'time_embedding_act_fn', 'conv_out_kernel', 'cross_attention_norm', 'attention_type', 'time_embedding_dim', 'encoder_hid_dim_type', 'resnet_time_scale_shift', 'addition_embed_type', 'only_cross_attention', 'num_attention_heads', 'resnet_skip_time_act', 'addition_time_embed_dim', 'class_embeddings_concat', 'mid_block_only_cross_attention', 'num_class_embeds'} was not found in config. Values will be initialized to default values.\n",
            "Loaded unet as UNet2DConditionModel from `unet` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loading pipeline components...: 100% 6/6 [00:00<00:00,  6.48it/s]\n",
            "{'timestep_spacing', 'variance_type', 'prediction_type', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  15% 300/2000 [08:13<36:05,  1.27s/it, loss=0.0148]02/14/2024 14:49:09 - INFO - __main__ - Running validation... \n",
            "Generating 4 images\n",
            "\n",
            "Loading pipeline components...:   0% 0/6 [00:00<?, ?it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  33% 2/6 [00:00<00:00, 17.96it/s]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  83% 5/6 [00:00<00:00,  7.86it/s]\u001b[A{'encoder_hid_dim', 'time_cond_proj_dim', 'resnet_out_scale_factor', 'mid_block_type', 'conv_in_kernel', 'upcast_attention', 'projection_class_embeddings_input_dim', 'addition_embed_type_num_heads', 'class_embed_type', 'time_embedding_type', 'timestep_post_act', 'transformer_layers_per_block', 'time_embedding_act_fn', 'conv_out_kernel', 'cross_attention_norm', 'attention_type', 'time_embedding_dim', 'encoder_hid_dim_type', 'resnet_time_scale_shift', 'addition_embed_type', 'only_cross_attention', 'num_attention_heads', 'resnet_skip_time_act', 'addition_time_embed_dim', 'class_embeddings_concat', 'mid_block_only_cross_attention', 'num_class_embeds'} was not found in config. Values will be initialized to default values.\n",
            "Loaded unet as UNet2DConditionModel from `unet` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loading pipeline components...: 100% 6/6 [00:00<00:00,  6.81it/s]\n",
            "{'timestep_spacing', 'variance_type', 'prediction_type', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  20% 400/2000 [11:16<33:48,  1.27s/it, loss=0.0373]02/14/2024 14:52:12 - INFO - __main__ - Running validation... \n",
            "Generating 4 images\n",
            "\n",
            "Loading pipeline components...:   0% 0/6 [00:00<?, ?it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  33% 2/6 [00:00<00:00, 17.74it/s]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  83% 5/6 [00:00<00:00,  7.61it/s]\u001b[A{'encoder_hid_dim', 'time_cond_proj_dim', 'resnet_out_scale_factor', 'mid_block_type', 'conv_in_kernel', 'upcast_attention', 'projection_class_embeddings_input_dim', 'addition_embed_type_num_heads', 'class_embed_type', 'time_embedding_type', 'timestep_post_act', 'transformer_layers_per_block', 'time_embedding_act_fn', 'conv_out_kernel', 'cross_attention_norm', 'attention_type', 'time_embedding_dim', 'encoder_hid_dim_type', 'resnet_time_scale_shift', 'addition_embed_type', 'only_cross_attention', 'num_attention_heads', 'resnet_skip_time_act', 'addition_time_embed_dim', 'class_embeddings_concat', 'mid_block_only_cross_attention', 'num_class_embeds'} was not found in config. Values will be initialized to default values.\n",
            "Loaded unet as UNet2DConditionModel from `unet` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loading pipeline components...: 100% 6/6 [00:00<00:00,  6.64it/s]\n",
            "{'timestep_spacing', 'variance_type', 'prediction_type', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  25% 500/2000 [14:20<31:46,  1.27s/it, loss=0.0187]02/14/2024 14:55:16 - INFO - accelerate.accelerator - Saving current state to flowerwoman-model/checkpoint-500\n",
            "02/14/2024 14:55:16 - INFO - accelerate.checkpointing - Optimizer state saved in flowerwoman-model/checkpoint-500/optimizer.bin\n",
            "02/14/2024 14:55:16 - INFO - accelerate.checkpointing - Random states saved in flowerwoman-model/checkpoint-500/random_states_0.pkl\n",
            "02/14/2024 14:55:16 - INFO - __main__ - Saved state to flowerwoman-model/checkpoint-500\n",
            "02/14/2024 14:55:16 - INFO - __main__ - Running validation... \n",
            "Generating 4 images\n",
            "\n",
            "Loading pipeline components...:   0% 0/6 [00:00<?, ?it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  33% 2/6 [00:00<00:00, 18.42it/s]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  83% 5/6 [00:00<00:00,  7.80it/s]\u001b[A{'encoder_hid_dim', 'time_cond_proj_dim', 'resnet_out_scale_factor', 'mid_block_type', 'conv_in_kernel', 'upcast_attention', 'projection_class_embeddings_input_dim', 'addition_embed_type_num_heads', 'class_embed_type', 'time_embedding_type', 'timestep_post_act', 'transformer_layers_per_block', 'time_embedding_act_fn', 'conv_out_kernel', 'cross_attention_norm', 'attention_type', 'time_embedding_dim', 'encoder_hid_dim_type', 'resnet_time_scale_shift', 'addition_embed_type', 'only_cross_attention', 'num_attention_heads', 'resnet_skip_time_act', 'addition_time_embed_dim', 'class_embeddings_concat', 'mid_block_only_cross_attention', 'num_class_embeds'} was not found in config. Values will be initialized to default values.\n",
            "Loaded unet as UNet2DConditionModel from `unet` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loading pipeline components...: 100% 6/6 [00:00<00:00,  6.80it/s]\n",
            "{'timestep_spacing', 'variance_type', 'prediction_type', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  30% 600/2000 [17:24<29:42,  1.27s/it, loss=0.107]02/14/2024 14:58:20 - INFO - __main__ - Running validation... \n",
            "Generating 4 images\n",
            "\n",
            "Loading pipeline components...:   0% 0/6 [00:00<?, ?it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  33% 2/6 [00:00<00:00, 18.31it/s]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  83% 5/6 [00:00<00:00,  7.73it/s]\u001b[A{'encoder_hid_dim', 'time_cond_proj_dim', 'resnet_out_scale_factor', 'mid_block_type', 'conv_in_kernel', 'upcast_attention', 'projection_class_embeddings_input_dim', 'addition_embed_type_num_heads', 'class_embed_type', 'time_embedding_type', 'timestep_post_act', 'transformer_layers_per_block', 'time_embedding_act_fn', 'conv_out_kernel', 'cross_attention_norm', 'attention_type', 'time_embedding_dim', 'encoder_hid_dim_type', 'resnet_time_scale_shift', 'addition_embed_type', 'only_cross_attention', 'num_attention_heads', 'resnet_skip_time_act', 'addition_time_embed_dim', 'class_embeddings_concat', 'mid_block_only_cross_attention', 'num_class_embeds'} was not found in config. Values will be initialized to default values.\n",
            "Loaded unet as UNet2DConditionModel from `unet` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loading pipeline components...: 100% 6/6 [00:00<00:00,  6.73it/s]\n",
            "{'timestep_spacing', 'variance_type', 'prediction_type', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  35% 700/2000 [20:25<27:00,  1.25s/it, loss=0.0837]02/14/2024 15:01:21 - INFO - __main__ - Running validation... \n",
            "Generating 4 images\n",
            "\n",
            "Loading pipeline components...:   0% 0/6 [00:00<?, ?it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  33% 2/6 [00:00<00:00, 18.81it/s]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  83% 5/6 [00:00<00:00,  8.40it/s]\u001b[A{'encoder_hid_dim', 'time_cond_proj_dim', 'resnet_out_scale_factor', 'mid_block_type', 'conv_in_kernel', 'upcast_attention', 'projection_class_embeddings_input_dim', 'addition_embed_type_num_heads', 'class_embed_type', 'time_embedding_type', 'timestep_post_act', 'transformer_layers_per_block', 'time_embedding_act_fn', 'conv_out_kernel', 'cross_attention_norm', 'attention_type', 'time_embedding_dim', 'encoder_hid_dim_type', 'resnet_time_scale_shift', 'addition_embed_type', 'only_cross_attention', 'num_attention_heads', 'resnet_skip_time_act', 'addition_time_embed_dim', 'class_embeddings_concat', 'mid_block_only_cross_attention', 'num_class_embeds'} was not found in config. Values will be initialized to default values.\n",
            "Loaded unet as UNet2DConditionModel from `unet` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loading pipeline components...: 100% 6/6 [00:00<00:00,  7.17it/s]\n",
            "{'timestep_spacing', 'variance_type', 'prediction_type', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  40% 800/2000 [23:23<24:48,  1.24s/it, loss=0.0161]02/14/2024 15:04:19 - INFO - __main__ - Running validation... \n",
            "Generating 4 images\n",
            "\n",
            "Loading pipeline components...:   0% 0/6 [00:00<?, ?it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  33% 2/6 [00:00<00:00, 18.55it/s]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  83% 5/6 [00:00<00:00,  8.19it/s]\u001b[A{'encoder_hid_dim', 'time_cond_proj_dim', 'resnet_out_scale_factor', 'mid_block_type', 'conv_in_kernel', 'upcast_attention', 'projection_class_embeddings_input_dim', 'addition_embed_type_num_heads', 'class_embed_type', 'time_embedding_type', 'timestep_post_act', 'transformer_layers_per_block', 'time_embedding_act_fn', 'conv_out_kernel', 'cross_attention_norm', 'attention_type', 'time_embedding_dim', 'encoder_hid_dim_type', 'resnet_time_scale_shift', 'addition_embed_type', 'only_cross_attention', 'num_attention_heads', 'resnet_skip_time_act', 'addition_time_embed_dim', 'class_embeddings_concat', 'mid_block_only_cross_attention', 'num_class_embeds'} was not found in config. Values will be initialized to default values.\n",
            "Loaded unet as UNet2DConditionModel from `unet` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loading pipeline components...: 100% 6/6 [00:00<00:00,  7.03it/s]\n",
            "{'timestep_spacing', 'variance_type', 'prediction_type', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  45% 900/2000 [26:21<22:43,  1.24s/it, loss=0.113]02/14/2024 15:07:17 - INFO - __main__ - Running validation... \n",
            "Generating 4 images\n",
            "\n",
            "Loading pipeline components...:   0% 0/6 [00:00<?, ?it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  33% 2/6 [00:00<00:00, 19.46it/s]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  83% 5/6 [00:00<00:00,  8.63it/s]\u001b[A{'encoder_hid_dim', 'time_cond_proj_dim', 'resnet_out_scale_factor', 'mid_block_type', 'conv_in_kernel', 'upcast_attention', 'projection_class_embeddings_input_dim', 'addition_embed_type_num_heads', 'class_embed_type', 'time_embedding_type', 'timestep_post_act', 'transformer_layers_per_block', 'time_embedding_act_fn', 'conv_out_kernel', 'cross_attention_norm', 'attention_type', 'time_embedding_dim', 'encoder_hid_dim_type', 'resnet_time_scale_shift', 'addition_embed_type', 'only_cross_attention', 'num_attention_heads', 'resnet_skip_time_act', 'addition_time_embed_dim', 'class_embeddings_concat', 'mid_block_only_cross_attention', 'num_class_embeds'} was not found in config. Values will be initialized to default values.\n",
            "Loaded unet as UNet2DConditionModel from `unet` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loading pipeline components...: 100% 6/6 [00:00<00:00,  7.31it/s]\n",
            "{'timestep_spacing', 'variance_type', 'prediction_type', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  50% 1000/2000 [29:25<21:14,  1.27s/it, loss=0.106]02/14/2024 15:10:21 - INFO - accelerate.accelerator - Saving current state to flowerwoman-model/checkpoint-1000\n",
            "02/14/2024 15:10:22 - INFO - accelerate.checkpointing - Optimizer state saved in flowerwoman-model/checkpoint-1000/optimizer.bin\n",
            "02/14/2024 15:10:22 - INFO - accelerate.checkpointing - Random states saved in flowerwoman-model/checkpoint-1000/random_states_0.pkl\n",
            "02/14/2024 15:10:22 - INFO - __main__ - Saved state to flowerwoman-model/checkpoint-1000\n",
            "02/14/2024 15:10:22 - INFO - __main__ - Running validation... \n",
            "Generating 4 images\n",
            "\n",
            "Loading pipeline components...:   0% 0/6 [00:00<?, ?it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  33% 2/6 [00:00<00:00, 18.31it/s]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  83% 5/6 [00:00<00:00,  7.69it/s]\u001b[A{'encoder_hid_dim', 'time_cond_proj_dim', 'resnet_out_scale_factor', 'mid_block_type', 'conv_in_kernel', 'upcast_attention', 'projection_class_embeddings_input_dim', 'addition_embed_type_num_heads', 'class_embed_type', 'time_embedding_type', 'timestep_post_act', 'transformer_layers_per_block', 'time_embedding_act_fn', 'conv_out_kernel', 'cross_attention_norm', 'attention_type', 'time_embedding_dim', 'encoder_hid_dim_type', 'resnet_time_scale_shift', 'addition_embed_type', 'only_cross_attention', 'num_attention_heads', 'resnet_skip_time_act', 'addition_time_embed_dim', 'class_embeddings_concat', 'mid_block_only_cross_attention', 'num_class_embeds'} was not found in config. Values will be initialized to default values.\n",
            "Loaded unet as UNet2DConditionModel from `unet` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loading pipeline components...: 100% 6/6 [00:00<00:00,  6.69it/s]\n",
            "{'timestep_spacing', 'variance_type', 'prediction_type', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  55% 1100/2000 [32:29<19:07,  1.28s/it, loss=0.0663]02/14/2024 15:13:26 - INFO - __main__ - Running validation... \n",
            "Generating 4 images\n",
            "\n",
            "Loading pipeline components...:   0% 0/6 [00:00<?, ?it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  33% 2/6 [00:00<00:00, 18.36it/s]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  83% 5/6 [00:00<00:00,  7.84it/s]\u001b[A{'encoder_hid_dim', 'time_cond_proj_dim', 'resnet_out_scale_factor', 'mid_block_type', 'conv_in_kernel', 'upcast_attention', 'projection_class_embeddings_input_dim', 'addition_embed_type_num_heads', 'class_embed_type', 'time_embedding_type', 'timestep_post_act', 'transformer_layers_per_block', 'time_embedding_act_fn', 'conv_out_kernel', 'cross_attention_norm', 'attention_type', 'time_embedding_dim', 'encoder_hid_dim_type', 'resnet_time_scale_shift', 'addition_embed_type', 'only_cross_attention', 'num_attention_heads', 'resnet_skip_time_act', 'addition_time_embed_dim', 'class_embeddings_concat', 'mid_block_only_cross_attention', 'num_class_embeds'} was not found in config. Values will be initialized to default values.\n",
            "Loaded unet as UNet2DConditionModel from `unet` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loading pipeline components...: 100% 6/6 [00:00<00:00,  6.81it/s]\n",
            "{'timestep_spacing', 'variance_type', 'prediction_type', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  60% 1200/2000 [35:34<17:00,  1.28s/it, loss=0.22]02/14/2024 15:16:30 - INFO - __main__ - Running validation... \n",
            "Generating 4 images\n",
            "\n",
            "Loading pipeline components...:   0% 0/6 [00:00<?, ?it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  33% 2/6 [00:00<00:00, 17.87it/s]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  83% 5/6 [00:00<00:00,  7.69it/s]\u001b[A{'encoder_hid_dim', 'time_cond_proj_dim', 'resnet_out_scale_factor', 'mid_block_type', 'conv_in_kernel', 'upcast_attention', 'projection_class_embeddings_input_dim', 'addition_embed_type_num_heads', 'class_embed_type', 'time_embedding_type', 'timestep_post_act', 'transformer_layers_per_block', 'time_embedding_act_fn', 'conv_out_kernel', 'cross_attention_norm', 'attention_type', 'time_embedding_dim', 'encoder_hid_dim_type', 'resnet_time_scale_shift', 'addition_embed_type', 'only_cross_attention', 'num_attention_heads', 'resnet_skip_time_act', 'addition_time_embed_dim', 'class_embeddings_concat', 'mid_block_only_cross_attention', 'num_class_embeds'} was not found in config. Values will be initialized to default values.\n",
            "Loaded unet as UNet2DConditionModel from `unet` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loading pipeline components...: 100% 6/6 [00:00<00:00,  6.72it/s]\n",
            "{'timestep_spacing', 'variance_type', 'prediction_type', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  65% 1300/2000 [38:37<14:29,  1.24s/it, loss=0.0691]02/14/2024 15:19:34 - INFO - __main__ - Running validation... \n",
            "Generating 4 images\n",
            "\n",
            "Loading pipeline components...:   0% 0/6 [00:00<?, ?it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  33% 2/6 [00:00<00:00, 18.07it/s]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  83% 5/6 [00:00<00:00,  7.70it/s]\u001b[A{'encoder_hid_dim', 'time_cond_proj_dim', 'resnet_out_scale_factor', 'mid_block_type', 'conv_in_kernel', 'upcast_attention', 'projection_class_embeddings_input_dim', 'addition_embed_type_num_heads', 'class_embed_type', 'time_embedding_type', 'timestep_post_act', 'transformer_layers_per_block', 'time_embedding_act_fn', 'conv_out_kernel', 'cross_attention_norm', 'attention_type', 'time_embedding_dim', 'encoder_hid_dim_type', 'resnet_time_scale_shift', 'addition_embed_type', 'only_cross_attention', 'num_attention_heads', 'resnet_skip_time_act', 'addition_time_embed_dim', 'class_embeddings_concat', 'mid_block_only_cross_attention', 'num_class_embeds'} was not found in config. Values will be initialized to default values.\n",
            "Loaded unet as UNet2DConditionModel from `unet` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loading pipeline components...: 100% 6/6 [00:00<00:00,  6.71it/s]\n",
            "{'timestep_spacing', 'variance_type', 'prediction_type', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  70% 1400/2000 [41:42<12:48,  1.28s/it, loss=0.0631]02/14/2024 15:22:38 - INFO - __main__ - Running validation... \n",
            "Generating 4 images\n",
            "\n",
            "Loading pipeline components...:   0% 0/6 [00:00<?, ?it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  33% 2/6 [00:00<00:00, 17.97it/s]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  83% 5/6 [00:00<00:00,  7.93it/s]\u001b[A{'encoder_hid_dim', 'time_cond_proj_dim', 'resnet_out_scale_factor', 'mid_block_type', 'conv_in_kernel', 'upcast_attention', 'projection_class_embeddings_input_dim', 'addition_embed_type_num_heads', 'class_embed_type', 'time_embedding_type', 'timestep_post_act', 'transformer_layers_per_block', 'time_embedding_act_fn', 'conv_out_kernel', 'cross_attention_norm', 'attention_type', 'time_embedding_dim', 'encoder_hid_dim_type', 'resnet_time_scale_shift', 'addition_embed_type', 'only_cross_attention', 'num_attention_heads', 'resnet_skip_time_act', 'addition_time_embed_dim', 'class_embeddings_concat', 'mid_block_only_cross_attention', 'num_class_embeds'} was not found in config. Values will be initialized to default values.\n",
            "Loaded unet as UNet2DConditionModel from `unet` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loading pipeline components...: 100% 6/6 [00:00<00:00,  6.84it/s]\n",
            "{'timestep_spacing', 'variance_type', 'prediction_type', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  75% 1500/2000 [44:46<10:36,  1.27s/it, loss=0.0533]02/14/2024 15:25:43 - INFO - accelerate.accelerator - Saving current state to flowerwoman-model/checkpoint-1500\n",
            "02/14/2024 15:25:43 - INFO - accelerate.checkpointing - Optimizer state saved in flowerwoman-model/checkpoint-1500/optimizer.bin\n",
            "02/14/2024 15:25:43 - INFO - accelerate.checkpointing - Random states saved in flowerwoman-model/checkpoint-1500/random_states_0.pkl\n",
            "02/14/2024 15:25:43 - INFO - __main__ - Saved state to flowerwoman-model/checkpoint-1500\n",
            "02/14/2024 15:25:43 - INFO - __main__ - Running validation... \n",
            "Generating 4 images\n",
            "\n",
            "Loading pipeline components...:   0% 0/6 [00:00<?, ?it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  33% 2/6 [00:00<00:00, 18.51it/s]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  83% 5/6 [00:00<00:00,  7.96it/s]\u001b[A{'encoder_hid_dim', 'time_cond_proj_dim', 'resnet_out_scale_factor', 'mid_block_type', 'conv_in_kernel', 'upcast_attention', 'projection_class_embeddings_input_dim', 'addition_embed_type_num_heads', 'class_embed_type', 'time_embedding_type', 'timestep_post_act', 'transformer_layers_per_block', 'time_embedding_act_fn', 'conv_out_kernel', 'cross_attention_norm', 'attention_type', 'time_embedding_dim', 'encoder_hid_dim_type', 'resnet_time_scale_shift', 'addition_embed_type', 'only_cross_attention', 'num_attention_heads', 'resnet_skip_time_act', 'addition_time_embed_dim', 'class_embeddings_concat', 'mid_block_only_cross_attention', 'num_class_embeds'} was not found in config. Values will be initialized to default values.\n",
            "Loaded unet as UNet2DConditionModel from `unet` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loading pipeline components...: 100% 6/6 [00:00<00:00,  6.82it/s]\n",
            "{'timestep_spacing', 'variance_type', 'prediction_type', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  80% 1600/2000 [47:51<08:29,  1.27s/it, loss=0.0233]02/14/2024 15:28:47 - INFO - __main__ - Running validation... \n",
            "Generating 4 images\n",
            "\n",
            "Loading pipeline components...:   0% 0/6 [00:00<?, ?it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  33% 2/6 [00:00<00:00, 17.66it/s]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  83% 5/6 [00:00<00:00,  7.61it/s]\u001b[A{'encoder_hid_dim', 'time_cond_proj_dim', 'resnet_out_scale_factor', 'mid_block_type', 'conv_in_kernel', 'upcast_attention', 'projection_class_embeddings_input_dim', 'addition_embed_type_num_heads', 'class_embed_type', 'time_embedding_type', 'timestep_post_act', 'transformer_layers_per_block', 'time_embedding_act_fn', 'conv_out_kernel', 'cross_attention_norm', 'attention_type', 'time_embedding_dim', 'encoder_hid_dim_type', 'resnet_time_scale_shift', 'addition_embed_type', 'only_cross_attention', 'num_attention_heads', 'resnet_skip_time_act', 'addition_time_embed_dim', 'class_embeddings_concat', 'mid_block_only_cross_attention', 'num_class_embeds'} was not found in config. Values will be initialized to default values.\n",
            "Loaded unet as UNet2DConditionModel from `unet` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loading pipeline components...: 100% 6/6 [00:00<00:00,  6.67it/s]\n",
            "{'timestep_spacing', 'variance_type', 'prediction_type', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  85% 1700/2000 [50:56<06:24,  1.28s/it, loss=0.0541]02/14/2024 15:31:52 - INFO - __main__ - Running validation... \n",
            "Generating 4 images\n",
            "\n",
            "Loading pipeline components...:   0% 0/6 [00:00<?, ?it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  33% 2/6 [00:00<00:00, 17.82it/s]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  83% 5/6 [00:00<00:00,  7.46it/s]\u001b[A{'encoder_hid_dim', 'time_cond_proj_dim', 'resnet_out_scale_factor', 'mid_block_type', 'conv_in_kernel', 'upcast_attention', 'projection_class_embeddings_input_dim', 'addition_embed_type_num_heads', 'class_embed_type', 'time_embedding_type', 'timestep_post_act', 'transformer_layers_per_block', 'time_embedding_act_fn', 'conv_out_kernel', 'cross_attention_norm', 'attention_type', 'time_embedding_dim', 'encoder_hid_dim_type', 'resnet_time_scale_shift', 'addition_embed_type', 'only_cross_attention', 'num_attention_heads', 'resnet_skip_time_act', 'addition_time_embed_dim', 'class_embeddings_concat', 'mid_block_only_cross_attention', 'num_class_embeds'} was not found in config. Values will be initialized to default values.\n",
            "Loaded unet as UNet2DConditionModel from `unet` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loading pipeline components...: 100% 6/6 [00:00<00:00,  6.55it/s]\n",
            "{'timestep_spacing', 'variance_type', 'prediction_type', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  90% 1800/2000 [54:00<04:15,  1.28s/it, loss=0.0287]02/14/2024 15:34:57 - INFO - __main__ - Running validation... \n",
            "Generating 4 images\n",
            "\n",
            "Loading pipeline components...:   0% 0/6 [00:00<?, ?it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  33% 2/6 [00:00<00:00, 18.18it/s]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  83% 5/6 [00:00<00:00,  7.35it/s]\u001b[A{'encoder_hid_dim', 'time_cond_proj_dim', 'resnet_out_scale_factor', 'mid_block_type', 'conv_in_kernel', 'upcast_attention', 'projection_class_embeddings_input_dim', 'addition_embed_type_num_heads', 'class_embed_type', 'time_embedding_type', 'timestep_post_act', 'transformer_layers_per_block', 'time_embedding_act_fn', 'conv_out_kernel', 'cross_attention_norm', 'attention_type', 'time_embedding_dim', 'encoder_hid_dim_type', 'resnet_time_scale_shift', 'addition_embed_type', 'only_cross_attention', 'num_attention_heads', 'resnet_skip_time_act', 'addition_time_embed_dim', 'class_embeddings_concat', 'mid_block_only_cross_attention', 'num_class_embeds'} was not found in config. Values will be initialized to default values.\n",
            "Loaded unet as UNet2DConditionModel from `unet` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loading pipeline components...: 100% 6/6 [00:00<00:00,  6.47it/s]\n",
            "{'timestep_spacing', 'variance_type', 'prediction_type', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
            "Steps:  95% 1900/2000 [57:06<02:06,  1.26s/it, loss=0.102]02/14/2024 15:38:02 - INFO - __main__ - Running validation... \n",
            "Generating 4 images\n",
            "\n",
            "Loading pipeline components...:   0% 0/6 [00:00<?, ?it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  33% 2/6 [00:00<00:00, 19.11it/s]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  83% 5/6 [00:00<00:00,  8.63it/s]\u001b[A{'encoder_hid_dim', 'time_cond_proj_dim', 'resnet_out_scale_factor', 'mid_block_type', 'conv_in_kernel', 'upcast_attention', 'projection_class_embeddings_input_dim', 'addition_embed_type_num_heads', 'class_embed_type', 'time_embedding_type', 'timestep_post_act', 'transformer_layers_per_block', 'time_embedding_act_fn', 'conv_out_kernel', 'cross_attention_norm', 'attention_type', 'time_embedding_dim', 'encoder_hid_dim_type', 'resnet_time_scale_shift', 'addition_embed_type', 'only_cross_attention', 'num_attention_heads', 'resnet_skip_time_act', 'addition_time_embed_dim', 'class_embeddings_concat', 'mid_block_only_cross_attention', 'num_class_embeds'} was not found in config. Values will be initialized to default values.\n",
            "Loaded unet as UNet2DConditionModel from `unet` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loading pipeline components...: 100% 6/6 [00:00<00:00,  7.34it/s]\n",
            "{'timestep_spacing', 'variance_type', 'prediction_type', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
            "Steps: 100% 2000/2000 [1:00:08<00:00,  1.25s/it, loss=0.161]02/14/2024 15:41:05 - INFO - accelerate.accelerator - Saving current state to flowerwoman-model/checkpoint-2000\n",
            "02/14/2024 15:41:05 - INFO - accelerate.checkpointing - Optimizer state saved in flowerwoman-model/checkpoint-2000/optimizer.bin\n",
            "02/14/2024 15:41:05 - INFO - accelerate.checkpointing - Random states saved in flowerwoman-model/checkpoint-2000/random_states_0.pkl\n",
            "02/14/2024 15:41:05 - INFO - __main__ - Saved state to flowerwoman-model/checkpoint-2000\n",
            "02/14/2024 15:41:05 - INFO - __main__ - Running validation... \n",
            "Generating 4 images\n",
            "\n",
            "Loading pipeline components...:   0% 0/6 [00:00<?, ?it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  33% 2/6 [00:00<00:00, 18.86it/s]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  83% 5/6 [00:00<00:00,  8.61it/s]\u001b[A{'encoder_hid_dim', 'time_cond_proj_dim', 'resnet_out_scale_factor', 'mid_block_type', 'conv_in_kernel', 'upcast_attention', 'projection_class_embeddings_input_dim', 'addition_embed_type_num_heads', 'class_embed_type', 'time_embedding_type', 'timestep_post_act', 'transformer_layers_per_block', 'time_embedding_act_fn', 'conv_out_kernel', 'cross_attention_norm', 'attention_type', 'time_embedding_dim', 'encoder_hid_dim_type', 'resnet_time_scale_shift', 'addition_embed_type', 'only_cross_attention', 'num_attention_heads', 'resnet_skip_time_act', 'addition_time_embed_dim', 'class_embeddings_concat', 'mid_block_only_cross_attention', 'num_class_embeds'} was not found in config. Values will be initialized to default values.\n",
            "Loaded unet as UNet2DConditionModel from `unet` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loading pipeline components...: 100% 6/6 [00:00<00:00,  7.33it/s]\n",
            "{'timestep_spacing', 'variance_type', 'prediction_type', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
            "Steps: 100% 2000/2000 [1:01:04<00:00,  1.25s/it, loss=0.0233]\n",
            "Loading pipeline components...:   0% 0/6 [00:00<?, ?it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  33% 2/6 [00:00<00:00, 19.93it/s]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loading pipeline components...: 100% 6/6 [00:00<00:00, 34.96it/s]\n",
            "Configuration saved in flowerwoman-model/vae/config.json\n",
            "Model weights saved in flowerwoman-model/vae/diffusion_pytorch_model.safetensors\n",
            "Configuration saved in flowerwoman-model/unet/config.json\n",
            "Model weights saved in flowerwoman-model/unet/diffusion_pytorch_model.safetensors\n",
            "Configuration saved in flowerwoman-model/scheduler/scheduler_config.json\n",
            "Configuration saved in flowerwoman-model/model_index.json\n",
            "02/14/2024 15:42:19 - INFO - __main__ - Running validation... \n",
            "Generating 4 images\n",
            "\n",
            "Loading pipeline components...:   0% 0/6 [00:00<?, ?it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  33% 2/6 [00:00<00:00, 15.36it/s]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "\n",
            "Loading pipeline components...:  83% 5/6 [00:00<00:00,  7.95it/s]\u001b[A{'encoder_hid_dim', 'time_cond_proj_dim', 'resnet_out_scale_factor', 'mid_block_type', 'conv_in_kernel', 'upcast_attention', 'projection_class_embeddings_input_dim', 'addition_embed_type_num_heads', 'class_embed_type', 'time_embedding_type', 'timestep_post_act', 'transformer_layers_per_block', 'time_embedding_act_fn', 'conv_out_kernel', 'cross_attention_norm', 'attention_type', 'time_embedding_dim', 'encoder_hid_dim_type', 'resnet_time_scale_shift', 'addition_embed_type', 'only_cross_attention', 'num_attention_heads', 'resnet_skip_time_act', 'addition_time_embed_dim', 'class_embeddings_concat', 'mid_block_only_cross_attention', 'num_class_embeds'} was not found in config. Values will be initialized to default values.\n",
            "Loaded unet as UNet2DConditionModel from `unet` subfolder of stabilityai/stable-diffusion-2-inpainting.\n",
            "Loading pipeline components...: 100% 6/6 [00:00<00:00,  6.78it/s]\n",
            "{'timestep_spacing', 'variance_type', 'prediction_type', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
            "Steps: 100% 2000/2000 [1:02:02<00:00,  1.86s/it, loss=0.0233]\n"
          ]
        }
      ],
      "source": [
        "%env MODEL_NAME=stabilityai/stable-diffusion-2-inpainting\n",
        "%env TRAIN_DIR=data/flowerwoman\n",
        "%env OUTPUT_DIR=flowerwoman-model\n",
        "\n",
        "!accelerate launch train_realfill.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "  --train_data_dir=$TRAIN_DIR \\\n",
        "  --output_dir=$OUTPUT_DIR \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=16 \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --unet_learning_rate=2e-4 \\\n",
        "  --text_encoder_learning_rate=4e-5 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=100 \\\n",
        "  --max_train_steps=2000 \\\n",
        "  --lora_rank=8 \\\n",
        "  --lora_dropout=0.1 \\\n",
        "  --lora_alpha=16"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env VAL_IMG=$TRAIN_DIR/target/target.png\n",
        "%env VAL_MASK=$TRAIN_DIR/target/mask.png\n",
        "%env OUTPUT_IMG_DIR=flowerwoman-results\n",
        "\n",
        "!accelerate launch infer.py \\\n",
        "    --model_path=$OUTPUT_DIR \\\n",
        "    --validation_image=$VAL_IMG \\\n",
        "    --validation_mask=$VAL_MASK \\\n",
        "    --output_dir=$OUTPUT_IMG_DIR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3m023PQGd_H1",
        "outputId": "1e5a8023-d02b-4d4a-d8e0-8a1b96f147d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: VAL_IMG=$TRAIN_DIR/target/target.png\n",
            "env: VAL_MASK=$TRAIN_DIR/target/mask.png\n",
            "env: OUTPUT_IMG_DIR=flowerwoman-results\n",
            "2024-02-14 16:45:46.802385: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-14 16:45:46.802448: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-14 16:45:46.804169: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-14 16:45:48.081612: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Loading pipeline components...: 100% 6/6 [00:00<00:00,  6.72it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/realfill/infer.py\", line 68, in <module>\n",
            "    image = Image.open(args.validation_image)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 3227, in open\n",
            "    fp = builtins.open(filename, \"rb\")\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '$TRAIN_DIR/target/target.png'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py\", line 47, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 986, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 628, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', 'infer.py', '--model_path=flowerwoman-model', '--validation_image=$TRAIN_DIR/target/target.png', '--validation_mask=$TRAIN_DIR/target/mask.png', '--output_dir=flowerwoman-results']' returned non-zero exit status 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r realfill.zip \\flowerwoman-results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nm40ryltdVNF",
        "outputId": "38321fd4-b0f5-4c7f-8ec6-b4550fd6f02f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: flowerwoman-results/ (stored 0%)\n",
            "updating: flowerwoman-results/0.png (deflated 0%)\n",
            "updating: flowerwoman-results/2.png (deflated 0%)\n",
            "updating: flowerwoman-results/14.png (deflated 0%)\n",
            "updating: flowerwoman-results/15.png (deflated 0%)\n",
            "updating: flowerwoman-results/12.png (deflated 0%)\n",
            "updating: flowerwoman-results/4.png (deflated 0%)\n",
            "updating: flowerwoman-results/10.png (deflated 0%)\n",
            "updating: flowerwoman-results/11.png (deflated 0%)\n",
            "updating: flowerwoman-results/8.png (deflated 0%)\n",
            "updating: flowerwoman-results/3.png (deflated 0%)\n",
            "updating: flowerwoman-results/6.png (deflated 0%)\n",
            "updating: flowerwoman-results/7.png (deflated 0%)\n",
            "updating: flowerwoman-results/9.png (deflated 0%)\n",
            "updating: flowerwoman-results/5.png (deflated 0%)\n",
            "updating: flowerwoman-results/13.png (deflated 0%)\n",
            "updating: flowerwoman-results/1.png (deflated 0%)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}